---
title: "P8105_hw2_dry2115"
author: "Dayoung Yu"
date: 2018-10-05
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
```


## Problem 1

Read and clean nyc transit data:

```{r}
transit_df = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), 
        entry, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The data set *transit_df* contains information on entrance specifications as well as available routes and ADA compliancy for each subway station in New York City. The variables included are: `r names(transit_df)`. These variables were specifically selected from the parent NYC_Transit_Subway_Entrance_And_Exit_Data dataset. The janitor function was used to clean the variable names and the entry variable was converted from character type to logical. The dimensions of *transit_df* are `r ncol(transit_df)` columns by `r nrow(transit_df)` rows. These data are not tidy because the route1-route11 columns should be collapsed into one column.



```{r}
stations_df = distinct(transit_df, station_name, line, .keep_all = TRUE)
  distinct_stations = nrow(stations_df)
  ada_compliant = nrow(filter(stations_df, ada == TRUE))
  
  without_vending = nrow(filter(stations_df, vending == "NO"))
  entrance_without_vending = nrow(filter(stations_df, vending == "NO", entry == TRUE))
  prop_entrance = round((entrance_without_vending / without_vending), digits = 3)
  
```

There are `r distinct_stations` distinct stations in the data set. `r ada_compliant` stations are ADA compliant. The proportion of non-vending stations that allow entry is `r prop_entrance`.


```{r}
transit_tidy_df = gather(transit_df, key = route_number, value = route_name, route1:route11)

  a_stations = 
    filter(transit_tidy_df, route_name == "A") %>%
    distinct(station_name, line) %>%
    nrow()
  
  compliant_a_stations = 
    filter(transit_tidy_df, route_name == "A", ada == TRUE) %>%
    distinct(station_name, line) %>%
    nrow()
```

`r a_stations` distinct stations serve the A train. Of those stations, `r compliant_a_stations` stations are ADA compliant.

## Problem 2

Read and clean Mr. Trash Wheels data:
```{r}
library(readxl)

trash_df = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  filter(dumpster != is.na(dumpster)) %>%
  mutate(
    sports_balls = as.integer(round(sports_balls, digits = 0))
  )

```

Read and clean precipitation data:
```{r}
prcp16_df = (
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, range = cell_rows(2:14)) %>%
  janitor::clean_names() %>%
  rename(total_prcp = total) %>%
  mutate(year = 2016))

prcp17_df = (
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, range = cell_rows(2:14)) %>%
  janitor::clean_names() %>%
  rename(total_prcp = total) %>%
  mutate(year = 2017))

```

Combine precipation data from 2016 and 2017:

```{r}
prcp1617_df = (
  bind_rows(prcp16_df, prcp17_df) %>%
  mutate(month = month.name[month]))

```

The Mr. Trash Wheel data set had `r nrow(trash_df)` observations. Key variables in this data set are the dates on which trash data was collected, the weight of trash in tons, the diffferent types of trash collected, and the number of homes powered by the waste energe. The median number of sports balls in a dumpster in 2016 was `r median(filter(trash_df, year == "2016")$sports_balls)`. The combined 2016 and 2017 precipitation data set had `r nrow(prcp1617_df)` observations. Key variables in this data set are month, year, and the total amount of precipitation in inches per month. The total precipitation in 2017 was `r sum(prcp17_df$total_prcp)` inches. 

## Problem 3

Install p8105 data package:
```{r}
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)
data(brfss_smart2010)
```

Clean brfss data:
```{r}
brfss_df = (
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  select(year, locationabbr, locationdesc, response, data_value) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(excellent_or_very_good = (excellent + very_good)))
  
```

Calculate location stats: 
```{r}
distinct_locations = nrow(distinct(brfss_df, locationdesc))
distinct_state = nrow(distinct(brfss_df, locationabbr))

brfss_df %>%
  group_by(locationabbr) %>%
  summarize(n = n()) %>%
  filter(min_rank(desc(n)) < 2)

```

In the BRFSS SMART 2010 data, there are `r distinct_locations` distinct locations. Since there are `r distinct_state` distinct states (including DC) in the data, every state is represented. New Jersey was the state that was observed the most.

Find median "Excellent" response values:
```{r}
brfss_df %>%
  group_by(year) %>%
  summarize(median_excellent = median(excellent, na.rm = TRUE))

```

In 2002, the median of the "Excellent" response value was 23.6.

Make a histogram and scatterplot of "Excellent" response values:
```{r}
brfss_df %>%
  filter(year == "2002") %>%
  ggplot(., aes(x = excellent)) + 
    geom_histogram() + 
    labs(
      title = "`Excellent` response values in 2002",
      x = "`Excellent` response values",
      y = "Count")


new_york = 
  brfss_df %>%
  filter(locationdesc == "NY - New York County")

queens = 
  brfss_df %>%
  filter(locationdesc == "NY - Queens County")

ny = (rbind(new_york, queens) %>%
        rename(County = locationdesc))
  

ggplot(ny, aes(x = year, y = excellent, color = County)) +
    geom_point() + 
    labs(
      title = "Proportion of 'Excellent' response values in New York County and Queens County",
      x = "Year",
      y = "Proportion of 'Excellent' respones values"
    ) + 
    theme(legend.position = "bottom")
```







